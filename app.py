# app.py
# -*- coding: utf-8 -*-
#
# æˆ¿å±‹åƒ¹æ ¼é æ¸¬ Streamlit æ‡‰ç”¨ï¼ˆç¾ä»£åŒ– UI + ä¸‰åˆ†é ï¼‰
# - è®€å– dataset/train.csv èˆ‡ dataset/test.csvï¼ˆå›ºå®šè·¯å¾‘ï¼‰
# - ç›®æ¨™ï¼šSalePrice
# - ç¼ºå€¼ç­–ç•¥ï¼š>50% ç¼ºå€¼ä¹‹æ¬„ä½åˆªé™¤ï¼›å…¶é¤˜æ•¸å€¼ä»¥ä¸­ä½æ•¸ã€é¡åˆ¥ä»¥çœ¾æ•¸
# - ç‰¹å¾µå·¥ç¨‹ï¼šOne-Hotï¼ˆé¡åˆ¥ï¼‰+ æ¨™æº–åŒ–ï¼ˆæ•¸å€¼ï¼‰
# - ç‰¹å¾µé¸æ“‡ï¼šKBest(f_regression) æˆ– L1/Lassoï¼ˆè‡ªå‹• Î±ï¼‰
# - æ¨¡å‹ï¼šNumPy é–‰å¼è§£ OLSï¼ˆæä¾› 95% CI/PIï¼‰ï¼Œå®Œå…¨ä¸ä¾è³´ statsmodels
#
# åŸ·è¡Œï¼š
#   streamlit run app.py
#
from pathlib import Path
import io
import time
import numpy as np
import pandas as pd
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt

import streamlit as st

from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.feature_selection import SelectKBest, f_regression
from sklearn.linear_model import LassoCV
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from scipy import sparse
from scipy.stats import t as student_t


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# åŸºæœ¬è¨­å®š
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(
    page_title="æˆ¿å±‹åƒ¹æ ¼é æ¸¬ â€” å¤šå…ƒç·šæ€§å›æ­¸",
    page_icon="ğŸ ",
    layout="wide"
)

DEFAULT_TARGET = "SalePrice"
BASE_DIR = Path(__file__).resolve().parent
TRAIN_PATH = BASE_DIR / "dataset" / "train.csv"
TEST_PATH  = BASE_DIR / "dataset" / "test.csv"

# ç’°å¢ƒå¥æª¢ï¼ˆä¸è¦æ±‚ä¸Šå‚³ï¼›å›ºå®šè®€å–è·¯å¾‘ï¼‰
if not TRAIN_PATH.exists() or not TEST_PATH.exists():
    st.error("æ‰¾ä¸åˆ°è³‡æ–™æª”ã€‚è«‹å»ºç«‹ `dataset/` è³‡æ–™å¤¾ä¸¦æ”¾å…¥ `train.csv` èˆ‡ `test.csv`ã€‚")
    st.stop()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# è³‡æ–™è¼‰å…¥èˆ‡å¿«å–
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_data(show_spinner=False)
def load_csvs():
    train_raw = pd.read_csv(TRAIN_PATH)
    test_raw  = pd.read_csv(TEST_PATH)
    return train_raw, test_raw

@st.cache_data(show_spinner=False)
def clean_data(df: pd.DataFrame):
    """æ™ºæ…§ç¼ºå€¼è™•ç†ï¼š
    - ç¼ºå€¼æ¯”ä¾‹ > 50%ï¼šæ•´æ¬„åˆªé™¤
    - å…¶é¤˜ï¼šæ•¸å€¼â†’ä¸­ä½æ•¸ï¼›é¡åˆ¥â†’çœ¾æ•¸ï¼ˆè‹¥ç„¡å‰‡ 'Unknown'ï¼‰
    å‚™è¨»ï¼šä¸åœ¨æ­¤è™•ä¸Ÿæ£„ target æ¬„ä½
    """
    df = df.copy()
    missing_ratio = df.isnull().sum() / len(df)
    cols_to_drop = missing_ratio[missing_ratio > 0.5].index.tolist()
    df = df.drop(columns=cols_to_drop)

    for col in df.columns:
        if df[col].isnull().sum() > 0:
            if pd.api.types.is_numeric_dtype(df[col]):
                df[col] = df[col].fillna(df[col].median())
            else:
                mode = df[col].mode()
                fillv = mode.iloc[0] if not mode.empty else "Unknown"
                df[col] = df[col].fillna(fillv)
    return df, cols_to_drop

def _make_ohe():
    """ç‚ºäº†å…¼å®¹ä¸åŒç‰ˆæœ¬ scikit-learn çš„ OneHotEncoder åƒæ•¸å·®ç•°ã€‚"""
    try:
        return OneHotEncoder(handle_unknown="ignore", sparse_output=False)
    except TypeError:
        # èˆŠç‰ˆ API
        return OneHotEncoder(handle_unknown="ignore", sparse=False)

def prepare_features(df: pd.DataFrame, target: str):
    """åˆ†é›¢ç‰¹å¾µèˆ‡ç›®æ¨™ã€å»ºç«‹ ColumnTransformerã€‚"""
    y = df[target].astype(float)
    X = df.drop(columns=[target])

    num_cols = [c for c in X.columns if pd.api.types.is_numeric_dtype(X[c])]
    cat_cols = [c for c in X.columns if not pd.api.types.is_numeric_dtype(X[c])]

    pre = ColumnTransformer(
        transformers=[
            ("num", StandardScaler(with_mean=True, with_std=True), num_cols),
            ("cat", _make_ohe(), cat_cols),
        ],
        remainder="drop",
    )
    return X, y, pre, num_cols, cat_cols

def fig_to_png(fig):
    """Matplotlib åœ–è½‰ PNG bytesã€‚"""
    buf = io.BytesIO()
    fig.savefig(buf, format="png", bbox_inches="tight", dpi=160)
    plt.close(fig)
    buf.seek(0)
    return buf.getvalue()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# OLSï¼ˆNumPy é–‰å¼è§£ï¼‰è¨ˆç®— 95% CI / 95% PI
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def ols_ci_pi_numpy(X_train: np.ndarray, y_train: np.ndarray,
                    X_test: np.ndarray, alpha: float = 0.05):
    """
    ä»¥ NumPyï¼ˆé–‰å¼è§£ï¼‰è¨ˆç®— OLS åƒæ•¸ã€å‡å€¼é æ¸¬ã€95% ä¿¡è³´å€é–“ï¼ˆCIï¼‰èˆ‡é æ¸¬å€é–“ï¼ˆPIï¼‰ã€‚
    X_* éœ€ç‚ºã€Œå·²å®Œæˆæ‰€æœ‰å‰è™•ç†/ç‰¹å¾µé¸æ“‡ã€å¾Œçš„è¨­è¨ˆçŸ©é™£ï¼ˆä¸å«å¸¸æ•¸æ¬„ï¼‰ã€‚
    """
    # åŠ ä¸Šå¸¸æ•¸é …
    Xtr = np.c_[np.ones((X_train.shape[0], 1)), X_train]
    Xte = np.c_[np.ones((X_test.shape[0], 1)),  X_test]

    # Î²Ì‚ = (X'X)^(-1) X'y ï¼›ä½¿ç”¨ pinv æ¯” inv ç©©å®š
    XtX_inv = np.linalg.pinv(Xtr.T @ Xtr)
    beta_hat = XtX_inv @ (Xtr.T @ y_train)

    # æ®˜å·®èˆ‡æ®˜å·®æ–¹å·® s^2 = RSS / (n - p)
    resid = y_train - Xtr @ beta_hat
    n, p = Xtr.shape
    dof = max(n - p, 1)
    sigma2 = float((resid @ resid) / dof)

    # é æ¸¬å‡å€¼èˆ‡æ¨™æº–èª¤
    y_mean = Xte @ beta_hat
    # Var(mean) = s^2 * x0' (X'X)^(-1) x0
    mean_var = np.einsum("ij,jk,ik->i", Xte, XtX_inv, Xte)
    se_mean = np.sqrt(np.maximum(sigma2 * mean_var, 0.0))
    # é æ¸¬å€é–“ Var(pred) = s^2 * (1 + x0'(X'X)^(-1)x0)
    se_pred = np.sqrt(np.maximum(sigma2 * (1.0 + mean_var), 0.0))

    # t è‡¨ç•Œå€¼
    tcrit = float(student_t.ppf(1.0 - alpha / 2.0, dof))

    ci_lo = y_mean - tcrit * se_mean
    ci_hi = y_mean + tcrit * se_mean
    pi_lo = y_mean - tcrit * se_pred
    pi_hi = y_mean + tcrit * se_pred

    return {
        "beta": beta_hat,          # [intercept, coef...]
        "y_mean": y_mean,          # é æ¸¬å‡å€¼
        "ci_lo": ci_lo, "ci_hi": ci_hi,
        "pi_lo": pi_lo, "pi_hi": pi_hi,
        "sigma2": sigma2, "dof": dof
    }


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# è¨“ç·´èˆ‡è©•ä¼°ä¸»æµç¨‹ï¼ˆå¯å‘¼å«ï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def train_and_evaluate(df_clean: pd.DataFrame, *,
                       test_size: float,
                       seed: int,
                       feat_sel: str,
                       k: int,
                       target: str = DEFAULT_TARGET):
    if target not in df_clean.columns:
        raise ValueError(f"ç›®æ¨™æ¬„ä½ã€Œ{target}ã€ä¸å­˜åœ¨æ–¼è³‡æ–™é›†ä¸­ã€‚")

    X, y, pre, num_cols, cat_cols = prepare_features(df_clean, target)
    Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=test_size, random_state=seed)

    # fit/transform
    pre.fit(Xtr)
    Xtr_t = pre.transform(Xtr)
    Xte_t = pre.transform(Xte)

    # å›æ¨ç‰¹å¾µåç¨±ï¼ˆæ•¸å€¼ + OHE å¾Œï¼‰
    feat_names = []
    if num_cols:
        feat_names += num_cols
    if cat_cols:
        ohe = pre.named_transformers_["cat"]
        try:
            feat_names += list(ohe.get_feature_names_out(cat_cols))
        except Exception:
            feat_names += [f"{c}" for c in cat_cols]

    # ç¨ å¯†åŒ–
    Xtr_d = Xtr_t.toarray() if sparse.issparse(Xtr_t) else np.asarray(Xtr_t)
    Xte_d = Xte_t.toarray() if sparse.issparse(Xte_t) else np.asarray(Xte_t)

    # ç‰¹å¾µé¸æ“‡
    selected_idx = np.arange(Xtr_d.shape[1])
    feat_sel_desc = "ä¸é€²è¡Œç‰¹å¾µé¸æ“‡"

    if feat_sel == "kbest":
        k_use = max(1, min(int(k), Xtr_d.shape[1]))
        skb = SelectKBest(score_func=f_regression, k=k_use)
        skb.fit(Xtr_d, ytr.values)
        selected_idx = np.where(skb.get_support())[0]
        feat_sel_desc = f"KBest (K={k_use})"

    elif feat_sel == "lasso":
        lasso = LassoCV(cv=5, random_state=seed, n_alphas=100, max_iter=5000)
        lasso.fit(Xtr_d, ytr.values)
        nz = np.where(np.abs(lasso.coef_) > 1e-8)[0]
        if len(nz) == 0:
            # è¬ä¸€å…¨ 0ï¼Œä¿åº•å– |coef| æœ€å¤§çš„ 10 å€‹
            k_fb = max(1, min(10, Xtr_d.shape[1]))
            nz = np.argsort(np.abs(lasso.coef_))[-k_fb:]
        selected_idx = np.sort(nz)
        feat_sel_desc = f"L1/Lassoï¼ˆ{len(selected_idx)} featuresï¼‰"

    # ç¯©é¸å¾Œè³‡æ–™
    Xtr_s = Xtr_d[:, selected_idx]
    Xte_s = Xte_d[:, selected_idx]
    feat_names_s = [feat_names[i] if i < len(feat_names) else f"f_{i}" for i in selected_idx]

    # â”€â”€ OLSï¼ˆNumPy é–‰å¼è§£ï¼‰èˆ‡å€é–“è¨ˆç®— â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    ols_out = ols_ci_pi_numpy(Xtr_s, ytr.values, Xte_s, alpha=0.05)
    yhat  = ols_out["y_mean"]
    ci_lo = ols_out["ci_lo"]; ci_hi = ols_out["ci_hi"]
    pi_lo = ols_out["pi_lo"]; pi_hi = ols_out["pi_hi"]

    # æŒ‡æ¨™
    mae = mean_absolute_error(yte.values, yhat)
    rmse = mean_squared_error(yte.values, yhat, squared=False)
    r2 = r2_score(yte.values, yhat)

    # ä¿‚æ•¸ï¼ˆå«æˆªè·åœ¨ beta[0]ï¼‰
    beta = np.asarray(ols_out["beta"]).reshape(-1)
    intercept = float(beta[0]) if beta.size > 0 else 0.0
    coefs = np.asarray(beta[1:], dtype=float)

    # Top-10 ä¿‚æ•¸
    names = feat_names_s if len(feat_names_s) == len(coefs) else [f"feature_{i}" for i in range(len(coefs))]
    if len(coefs) > 0 and np.any(np.isfinite(coefs)):
        order = np.argsort(-np.abs(coefs))
        top = [(i + 1, names[idx], float(coefs[idx])) for i, idx in enumerate(order[: min(10, len(coefs))])]
    else:
        top = [(1, "N/A", 0.0)]

    # è¦–è¦ºåŒ–ï¼šPredicted vs Actualï¼ˆæ’åºä»¥ä¾¿è§€å¯Ÿè¶¨å‹¢ï¼‰
    order_idx = np.argsort(yte.values)
    y_true = yte.values[order_idx]
    y_pred = yhat[order_idx]
    ci_lo_s, ci_hi_s = ci_lo[order_idx], ci_hi[order_idx]
    pi_lo_s, pi_hi_s = pi_lo[order_idx], pi_hi[order_idx]

    fig = plt.figure(figsize=(8.5, 6.2))
    ax = fig.add_subplot(111)
    ax.fill_between(range(len(y_true)), pi_lo_s, pi_hi_s, alpha=0.12, label="95% Prediction Interval")
    ax.fill_between(range(len(y_true)), ci_lo_s, ci_hi_s, alpha=0.20, label="95% Confidence Interval")
    ax.plot(range(len(y_true)), y_true, lw=2, label="Actual", marker="o", markersize=3, alpha=0.75)
    ax.plot(range(len(y_true)), y_pred, lw=2, label="Predicted", marker="s", markersize=3, alpha=0.75)
    ax.set_title("Predicted vs Actual (with 95% CI / PI)", fontsize=12, fontweight="bold")
    ax.set_xlabel("Validation Samples (sorted by Actual)")
    ax.set_ylabel("SalePrice")
    ax.grid(True, alpha=0.15, linestyle="--")
    ax.legend(loc="best", fontsize=9, framealpha=0.95)
    fig.tight_layout()

    return {
        "n_train": int(Xtr_s.shape[0]),
        "n_test": int(Xte_s.shape[0]),
        "n_features": int(Xtr_s.shape[1]),
        "target": target,
        "feat_sel_desc": feat_sel_desc,
        "mae": float(mae),
        "rmse": float(rmse),
        "r2": float(r2),
        "top_coefs": top,
        "figure": fig,
    }


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# é é¢ UI
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown(
    "<h1 style='margin-bottom:0'>æˆ¿å±‹åƒ¹æ ¼é æ¸¬</h1>"
    "<div style='color:#64748b;margin-top:4px'>Multiple Linear Regression with Advanced Feature Selection</div>",
    unsafe_allow_html=True
)
st.markdown("---")

# è¼‰å…¥èˆ‡æ¸…ç†
train_raw, test_raw = load_csvs()
train_clean, dropped_cols = clean_data(train_raw.copy())
test_clean, _ = clean_data(test_raw.copy())

# å¿«é€Ÿçµ±è¨ˆ
train_n_rows, n_cols = train_clean.shape
test_n_rows = test_clean.shape[0]

# Tabs
tab_preview, tab_train, tab_results = st.tabs(["ğŸ“„ è³‡æ–™é è¦½", "âš™ï¸ è¨“ç·´è¨­å®š", "ğŸ“ˆ è¨“ç·´çµæœ"])

with tab_preview:
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("è¨“ç·´æ¨£æœ¬", f"{train_n_rows:,}")
    c2.metric("æ¸¬è©¦æ¨£æœ¬", f"{test_n_rows:,}")
    c3.metric("ç‰¹å¾µæ¬„ä½æ•¸", f"{n_cols:,}")
    c4.metric("é æ¸¬ç›®æ¨™", DEFAULT_TARGET)

    st.success("å·²å®Œæˆç¼ºå€¼æ¸…ç†ï¼›>50% ç¼ºå€¼æ¬„ä½å·²åˆªé™¤ä¸¦è¨˜éŒ„ã€‚")
    st.caption(f"åˆªé™¤æ¬„ä½æ•¸ï¼ˆ>50% ç¼ºå€¼ï¼‰ï¼š{len(dropped_cols)}")
    with st.expander("æŸ¥çœ‹è¢«åˆªæ¬„ä½åç¨±", expanded=False):
        if len(dropped_cols) == 0:
            st.write("ï¼ˆç„¡ï¼‰")
        else:
            st.write(dropped_cols)

    st.subheader("è¨“ç·´è³‡æ–™å‰ 10 åˆ—")
    st.dataframe(train_clean.head(10), use_container_width=True)

with tab_train:
    st.subheader("è¨“ç·´é…ç½®")
    colA, colB, colC, colD = st.columns([1, 1, 1, 1])
    with colA:
        test_size = st.selectbox("é©—è­‰é›†æ¯”ä¾‹", options=[0.2, 0.25, 0.3], index=0, format_func=lambda x: f"{int(x*100)}%")
    with colB:
        seed = st.number_input("éš¨æ©Ÿç¨®å­", min_value=1, value=42, step=1)
    with colC:
        feat_sel = st.selectbox("ç‰¹å¾µé¸æ“‡æ–¹æ³•", options=["kbest", "lasso"], index=0,
                                format_func=lambda v: "KBest (f_regression)" if v == "kbest" else "L1 / Lassoï¼ˆè‡ªå‹• Î±ï¼‰")
    with colD:
        k = st.number_input("K å€¼ï¼ˆKBestï¼‰", min_value=1, value=10, step=1)

    start_btn = st.button("é–‹å§‹è¨“ç·´", type="primary")

    if start_btn:
        # å‡é€²åº¦æ¢ï¼šå¢é€²é«”é©—ï¼ˆä¸å½±éŸ¿å¯¦éš›é‹ç®—ï¼‰
        progress = st.progress(0, text="è¨“ç·´ä¸­...è«‹ç¨å€™")
        for p in [10, 25, 45, 65, 80, 90]:
            progress.progress(p, text="è¨“ç·´ä¸­...è«‹ç¨å€™")
            time.sleep(0.15)

        try:
            results = train_and_evaluate(
                train_clean,
                test_size=float(test_size),
                seed=int(seed),
                feat_sel=feat_sel,
                k=int(k),
                target=DEFAULT_TARGET
            )
            # è¨“ç·´çµæŸ
            progress.progress(100, text="å®Œæˆï¼")
            st.success("âœ… è¨“ç·´å®Œæˆï¼è«‹åˆ‡æ›åˆ°ã€ŒğŸ“ˆ è¨“ç·´çµæœã€åˆ†é æŸ¥çœ‹ã€‚")
            # å„²å­˜æ–¼ session_state ä»¥ä¾¿çµæœé é¡¯ç¤º
            st.session_state["results"] = results
        except Exception as e:
            progress.empty()
            st.error(f"âŒ è¨“ç·´å¤±æ•—ï¼š{e}")

with tab_results:
    results = st.session_state.get("results")
    if not results:
        st.info("å°šç„¡çµæœã€‚è«‹åˆ°ã€Œâš™ï¸ è¨“ç·´è¨­å®šã€åˆ†é åŸ·è¡Œè¨“ç·´ã€‚")
    else:
        c1, c2, c3, c4, c5 = st.columns(5)
        c1.metric("è¨“ç·´æ¨£æœ¬", f"{results['n_train']:,}")
        c2.metric("é©—è­‰æ¨£æœ¬", f"{results['n_test']:,}")
        c3.metric("ä½¿ç”¨ç‰¹å¾µæ•¸", f"{results['n_features']:,}")
        c4.metric("MAE", f"{results['mae']:,.2f}")
        c5.metric("RMSE", f"{results['rmse']:,.2f}")
        st.metric(label="RÂ²", value=f"{results['r2']:.4f}")
        st.caption(f"ç‰¹å¾µé¸æ“‡ï¼š{results['feat_sel_desc']}ï½œç›®æ¨™ï¼š{results['target']}")

        # Top-10 ä¿‚æ•¸
        st.subheader("ç‰¹å¾µä¿‚æ•¸ï¼ˆTop 10 by |coef|ï¼‰")
        coef_df = pd.DataFrame(results["top_coefs"], columns=["Rank", "Feature", "Coefficient"])
        st.dataframe(coef_df, use_container_width=True, hide_index=True)

        # åœ–
        st.subheader("Predicted vs Actualï¼ˆå« 95% CI / 95% PIï¼‰")
        st.pyplot(results["figure"], clear_figure=True)

        st.caption("CI = Confidence Intervalï¼ˆå¹³å‡é æ¸¬å€é–“ï¼‰ï¼›PI = Prediction Intervalï¼ˆæ–°è§€æ¸¬å€é–“ï¼‰")
