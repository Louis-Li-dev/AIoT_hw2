"""
é­šé¡é«”é‡é æ¸¬ç³»çµ± - ä½¿ç”¨ Lasso è¿´æ­¸
Fish Weight Prediction System using Lasso Regression

ä½œæ¥­è¦æ±‚ï¼š
1. ä½¿ç”¨ chatGPT å·¥å…·åˆ©ç”¨ CRISP-DM æ¨¡æ¿è§£æ±ºå¤šå…ƒå›æ­¸ Regression Problem
2. Step 1: çˆ¬èŸ²æŠ“å– Boston æˆ¿åƒ¹ (æœ¬å°ˆæ¡ˆæ”¹ç”¨é­šé¡è³‡æ–™é›†)
3. Step 2: Preprocessing: train test split
4. Step 3: Build Model using Lasso
5. Step 4: Evaluation: MSE, MAE, R2 metrics çš„æ„ç¾©, overfit and underfit çš„åˆ¤æ–·
6. Step 5: Deployment

åŸ·è¡Œæ–¹å¼: streamlit run app.py
ä½¿ç”¨ PATH è®Šæ•¸è®€å– CSV æª”æ¡ˆ
"""

import streamlit as st
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import Lasso
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import matplotlib.pyplot as plt
import seaborn as sns

# è¨­å®šä¸­æ–‡å­—å‹
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'Microsoft JhengHei', 'SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# è¨­å®šé é¢é…ç½®
st.set_page_config(
    page_title="é­šé¡é«”é‡é æ¸¬ç³»çµ±",
    page_icon="ğŸŸ",
    layout="wide"
)

# ==================== PATH è®Šæ•¸è¨­å®š ====================
# è«‹å°‡ PATH è¨­å®šç‚ºæ‚¨çš„ CSV æª”æ¡ˆè·¯å¾‘
PATH = "./dataset/Fishers maket.csv"  # ä¿®æ”¹æ­¤è·¯å¾‘ç‚ºæ‚¨çš„ CSV æª”æ¡ˆä½ç½®

# ==================== æ¨™é¡Œ ====================
st.title("ğŸŸ é­šé¡é«”é‡é æ¸¬ç³»çµ± - Lasso è¿´æ­¸åˆ†æ")
st.markdown("### ä½¿ç”¨ CRISP-DM æ–¹æ³•è«–é€²è¡Œå¤šå…ƒè¿´æ­¸å•é¡Œè§£æ±º")
st.markdown("---")

# ==================== Step 1: è³‡æ–™è¼‰å…¥ ====================
st.header("ğŸ“Š Step 1: è³‡æ–™è¼‰å…¥")
st.markdown("""
**CRISP-DM éšæ®µ**: Business Understanding & Data Understanding

åœ¨æœ¬å°ˆæ¡ˆä¸­ï¼Œæˆ‘å€‘ä½¿ç”¨é­šé¡è³‡æ–™é›†ä¾†é æ¸¬é­šçš„é«”é‡ã€‚
è³‡æ–™é›†åŒ…å«ä»¥ä¸‹ç‰¹å¾µï¼š
- **Species**: é­šçš„ç¨®é¡ï¼ˆé¡åˆ¥è®Šæ•¸ï¼‰
- **Length1, Length2, Length3**: ä¸åŒæ¸¬é‡æ–¹å¼çš„é•·åº¦ï¼ˆå‚ç›´é•·åº¦ã€å°è§’ç·šé•·åº¦ã€äº¤å‰é•·åº¦ï¼‰
- **Height**: é«˜åº¦
- **Width**: å¯¬åº¦
- **Weight**: é«”é‡ï¼ˆç›®æ¨™è®Šæ•¸ï¼Œæˆ‘å€‘è¦é æ¸¬çš„å€¼ï¼‰
""")

try:
    # ä½¿ç”¨ pandas è®€å– CSV æª”æ¡ˆ
    df = pd.read_csv(PATH)
    st.success(f"âœ… æˆåŠŸè¼‰å…¥è³‡æ–™ï¼æª”æ¡ˆè·¯å¾‘: {PATH}")
except FileNotFoundError:
    st.error(f"âŒ æ‰¾ä¸åˆ°æª”æ¡ˆ: {PATH}")
    st.info("è«‹ç¢ºèª PATH è®Šæ•¸è¨­å®šæ­£ç¢ºï¼Œæˆ–å°‡ CSV æª”æ¡ˆæ”¾åœ¨æ­£ç¢ºä½ç½®")
    st.stop()
except Exception as e:
    st.error(f"âŒ è®€å–æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    st.stop()

# é¡¯ç¤ºè³‡æ–™
st.subheader("ğŸ“‹ è³‡æ–™é è¦½")
col1, col2 = st.columns([2, 1])

with col1:
    st.write("**å‰ 10 ç­†è³‡æ–™**")
    st.dataframe(df.head(10), use_container_width=True)

with col2:
    st.write("**è³‡æ–™åŸºæœ¬è³‡è¨Š**")
    st.metric("ç¸½æ¨£æœ¬æ•¸", len(df))
    st.metric("ç‰¹å¾µæ•¸é‡", len(df.columns) - 1)
    st.metric("ç›®æ¨™è®Šæ•¸", "Weight")
    
    # æª¢æŸ¥ç¼ºå¤±å€¼
    missing_values = df.isnull().sum().sum()
    st.metric("ç¼ºå¤±å€¼ç¸½æ•¸", missing_values)

# è³‡æ–™æè¿°çµ±è¨ˆ
st.subheader("ğŸ“ˆ æè¿°æ€§çµ±è¨ˆ")
st.dataframe(df.describe(), use_container_width=True)

# è¦–è¦ºåŒ–ï¼šç›®æ¨™è®Šæ•¸åˆ†ä½ˆ
st.subheader("ğŸ¯ ç›®æ¨™è®Šæ•¸ (Weight) åˆ†ä½ˆ")
fig, ax = plt.subplots(figsize=(10, 4))
ax.hist(df['Weight'], bins=20, color='skyblue', edgecolor='black')
ax.set_xlabel('é«”é‡ (Weight)', fontsize=12)
ax.set_ylabel('é »ç‡', fontsize=12)
ax.set_title('é­šé¡é«”é‡åˆ†ä½ˆåœ–', fontsize=14)
ax.grid(True, alpha=0.3)
st.pyplot(fig)

# ==================== Step 2: è³‡æ–™é è™•ç†èˆ‡åˆ†å‰² ====================
st.markdown("---")
st.header("âš™ï¸ Step 2: è³‡æ–™é è™•ç† (Preprocessing) èˆ‡è¨“ç·´æ¸¬è©¦é›†åˆ†å‰²")

st.markdown("""
**CRISP-DM éšæ®µ**: Data Preparation

### é è™•ç†æ­¥é©Ÿï¼š
1. **ç‰¹å¾µèˆ‡ç›®æ¨™è®Šæ•¸åˆ†é›¢**: å°‡ Weight ä½œç‚ºç›®æ¨™è®Šæ•¸ (y)ï¼Œå…¶ä»–æ¬„ä½ä½œç‚ºç‰¹å¾µ (X)
2. **é¡åˆ¥è®Šæ•¸ç·¨ç¢¼**: ä½¿ç”¨ One-Hot Encoding è™•ç† Species é¡åˆ¥è®Šæ•¸
3. **è¨“ç·´æ¸¬è©¦é›†åˆ†å‰²**: å°‡è³‡æ–™åˆ†ç‚ºè¨“ç·´é›† (80%) å’Œæ¸¬è©¦é›† (20%)
4. **ç‰¹å¾µæ¨™æº–åŒ–**: ä½¿ç”¨ StandardScaler é€²è¡Œæ¨™æº–åŒ–ï¼Œä½¿ç‰¹å¾µå…·æœ‰ç›¸åŒçš„å°ºåº¦

**ç‚ºä»€éº¼éœ€è¦æ¨™æº–åŒ–ï¼Ÿ**
- Lasso è¿´æ­¸å°ç‰¹å¾µå°ºåº¦æ•æ„Ÿ
- æ¨™æº–åŒ–å¾Œæ‰€æœ‰ç‰¹å¾µå…·æœ‰å¹³å‡å€¼=0ï¼Œæ¨™æº–å·®=1
- æœ‰åŠ©æ–¼æ¨¡å‹æ›´å¿«æ”¶æ–‚ï¼Œæå‡é æ¸¬æ•ˆèƒ½
""")

# å´é‚Šæ¬„åƒæ•¸è¨­å®š
st.sidebar.header("ğŸ›ï¸ æ¨¡å‹åƒæ•¸è¨­å®š")
test_size = st.sidebar.slider("æ¸¬è©¦é›†æ¯”ä¾‹", 0.1, 0.4, 0.2, 0.05)
random_state = st.sidebar.number_input("éš¨æ©Ÿç¨®å­", 1, 100, 42)

# è³‡æ–™é è™•ç†
@st.cache_data
def preprocess_data(dataframe, test_sz, rand_state):
    """è³‡æ–™é è™•ç†å‡½æ•¸"""
    # åˆ†é›¢ç‰¹å¾µå’Œç›®æ¨™è®Šæ•¸
    X = dataframe.drop('Weight', axis=1)
    y = dataframe['Weight']
    
    # One-Hot Encoding è™•ç†é¡åˆ¥è®Šæ•¸
    if 'Species' in X.columns:
        X = pd.get_dummies(X, columns=['Species'], drop_first=True)
    
    # è¨“ç·´æ¸¬è©¦é›†åˆ†å‰²
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_sz, random_state=rand_state
    )
    
    # ç‰¹å¾µæ¨™æº–åŒ–
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    return X_train_scaled, X_test_scaled, y_train, y_test, scaler, X.columns

X_train, X_test, y_train, y_test, scaler, feature_names = preprocess_data(df, test_size, random_state)

# é¡¯ç¤ºåˆ†å‰²çµæœ
col1, col2, col3 = st.columns(3)
with col1:
    st.metric("è¨“ç·´é›†æ¨£æœ¬æ•¸", len(X_train))
with col2:
    st.metric("æ¸¬è©¦é›†æ¨£æœ¬æ•¸", len(X_test))
with col3:
    st.metric("ç‰¹å¾µæ•¸é‡ï¼ˆç·¨ç¢¼å¾Œï¼‰", X_train.shape[1])

st.success("âœ… è³‡æ–™é è™•ç†å®Œæˆï¼")

# ==================== Step 3: å»ºç«‹ Lasso æ¨¡å‹ ====================
st.markdown("---")
st.header("ğŸ¤– Step 3: å»ºç«‹æ¨¡å‹ - Lasso è¿´æ­¸")

st.markdown("""
**CRISP-DM éšæ®µ**: Modeling

### ä»€éº¼æ˜¯ Lasso è¿´æ­¸ï¼Ÿ
**Lasso (Least Absolute Shrinkage and Selection Operator)** æ˜¯ä¸€ç¨®ç·šæ€§è¿´æ­¸æ–¹æ³•ï¼Œä½¿ç”¨ L1 æ­£å‰‡åŒ–ã€‚

**Lasso çš„ç‰¹é»ï¼š**
- âœ¨ **ç‰¹å¾µé¸æ“‡**: å¯ä»¥å°‡ä¸é‡è¦çš„ç‰¹å¾µä¿‚æ•¸ç¸®æ¸›ç‚º 0ï¼Œè‡ªå‹•é€²è¡Œç‰¹å¾µé¸æ“‡
- ğŸ¯ **é˜²æ­¢éæ“¬åˆ**: L1 æ­£å‰‡åŒ–æ‡²ç½°é …å¯ä»¥é˜²æ­¢æ¨¡å‹éåº¦è¤‡é›œ
- ğŸ“Š **ç¨€ç–è§£**: ç”¢ç”Ÿç¨€ç–æ¨¡å‹ï¼Œåªä¿ç•™é‡è¦ç‰¹å¾µ

**Alpha åƒæ•¸**ï¼šæ§åˆ¶æ­£å‰‡åŒ–å¼·åº¦
- Alpha è¶Šå¤§ â†’ æ­£å‰‡åŒ–è¶Šå¼· â†’ æ›´å¤šä¿‚æ•¸è¢«å£“ç¸®ç‚º 0 â†’ æ¨¡å‹è¶Šç°¡å–®
- Alpha è¶Šå° â†’ æ­£å‰‡åŒ–è¶Šå¼± â†’ æ¥è¿‘æ™®é€šç·šæ€§è¿´æ­¸
""")

# Alpha åƒæ•¸è¨­å®š
alpha = st.sidebar.slider("Alpha (æ­£å‰‡åŒ–å¼·åº¦)", 0.01, 10.0, 1.0, 0.1)

# è¨“ç·´æ¨¡å‹
@st.cache_resource
def train_lasso_model(X_tr, y_tr, alpha_param):
    """è¨“ç·´ Lasso æ¨¡å‹"""
    model = Lasso(alpha=alpha_param, random_state=42, max_iter=10000)
    model.fit(X_tr, y_tr)
    return model

model = train_lasso_model(X_train, y_train, alpha)

st.success(f"âœ… Lasso æ¨¡å‹è¨“ç·´å®Œæˆï¼Alpha = {alpha}")

# é¡¯ç¤ºç‰¹å¾µé‡è¦æ€§
st.subheader("ğŸ“Š ç‰¹å¾µä¿‚æ•¸ (Feature Coefficients)")
st.markdown("ä¿‚æ•¸çµ•å°å€¼è¶Šå¤§ï¼Œè¡¨ç¤ºè©²ç‰¹å¾µå°é æ¸¬çµæœçš„å½±éŸ¿è¶Šå¤§ã€‚ä¿‚æ•¸ç‚º 0 è¡¨ç¤ºè©²ç‰¹å¾µè¢« Lasso æ’é™¤ã€‚")

coef_df = pd.DataFrame({
    'ç‰¹å¾µåç¨±': feature_names,
    'ä¿‚æ•¸': model.coef_,
    'çµ•å°å€¼': np.abs(model.coef_)
}).sort_values('çµ•å°å€¼', ascending=False)

fig, ax = plt.subplots(figsize=(10, 6))
colors = ['green' if x != 0 else 'gray' for x in coef_df['ä¿‚æ•¸']]
ax.barh(coef_df['ç‰¹å¾µåç¨±'], coef_df['ä¿‚æ•¸'], color=colors)
ax.set_xlabel('ä¿‚æ•¸å€¼', fontsize=12)
ax.set_title('Lasso è¿´æ­¸ç‰¹å¾µä¿‚æ•¸', fontsize=14)
ax.axvline(x=0, color='black', linestyle='--', linewidth=0.8)
ax.grid(True, alpha=0.3, axis='x')
st.pyplot(fig)

st.dataframe(coef_df, use_container_width=True)

# ==================== Step 4: æ¨¡å‹è©•ä¼° ====================
st.markdown("---")
st.header("ğŸ“ˆ Step 4: æ¨¡å‹è©•ä¼°")

st.markdown("""
**CRISP-DM éšæ®µ**: Evaluation

### è©•ä¼°æŒ‡æ¨™èªªæ˜ï¼š

**1. MSE (Mean Squared Error, å‡æ–¹èª¤å·®)**
- è¨ˆç®—æ–¹å¼ï¼šé æ¸¬èª¤å·®çš„å¹³æ–¹å¹³å‡å€¼
- æ„ç¾©ï¼šMSE è¶Šå°ï¼Œæ¨¡å‹é æ¸¬è¶Šæº–ç¢º
- ç‰¹é»ï¼šå°é›¢ç¾¤å€¼ï¼ˆoutliersï¼‰éå¸¸æ•æ„Ÿï¼Œå› ç‚ºèª¤å·®è¢«å¹³æ–¹æ”¾å¤§

**2. MAE (Mean Absolute Error, å¹³å‡çµ•å°èª¤å·®)**
- è¨ˆç®—æ–¹å¼ï¼šé æ¸¬èª¤å·®çµ•å°å€¼çš„å¹³å‡
- æ„ç¾©ï¼šMAE è¶Šå°ï¼Œæ¨¡å‹é æ¸¬è¶Šæº–ç¢º
- ç‰¹é»ï¼šè¼ƒä¸å—é›¢ç¾¤å€¼å½±éŸ¿ï¼Œæ›´èƒ½åæ˜ å¹³å‡èª¤å·®

**3. RÂ² (R-squared, æ±ºå®šä¿‚æ•¸)**
- ç¯„åœï¼š-âˆ åˆ° 1
- æ„ç¾©ï¼šæ¨¡å‹è§£é‡‹ç›®æ¨™è®Šæ•¸è®Šç•°çš„æ¯”ä¾‹
  - RÂ² = 1: å®Œç¾é æ¸¬
  - RÂ² = 0: æ¨¡å‹è¡¨ç¾ç­‰åŒæ–¼ä½¿ç”¨å¹³å‡å€¼é æ¸¬
  - RÂ² < 0: æ¨¡å‹è¡¨ç¾æ¯”ä½¿ç”¨å¹³å‡å€¼é‚„å·®

### Overfit (éæ“¬åˆ) vs Underfit (æ¬ æ“¬åˆ) åˆ¤æ–·ï¼š

**ğŸ”´ Overfit (éæ“¬åˆ)ï¼š**
- ç¾è±¡ï¼šè¨“ç·´é›†è¡¨ç¾éå¸¸å¥½ï¼Œä½†æ¸¬è©¦é›†è¡¨ç¾å¾ˆå·®
- åˆ¤æ–·ï¼šè¨“ç·´ RÂ² >> æ¸¬è©¦ RÂ²ï¼ˆä¾‹å¦‚ï¼šè¨“ç·´ RÂ²=0.95ï¼Œæ¸¬è©¦ RÂ²=0.60ï¼‰
- åŸå› ï¼šæ¨¡å‹éåº¦å­¸ç¿’è¨“ç·´è³‡æ–™çš„ç´°ç¯€å’Œé›œè¨Š
- è§£æ±ºæ–¹æ³•ï¼šå¢åŠ æ­£å‰‡åŒ–å¼·åº¦ï¼ˆå¢å¤§ alphaï¼‰ã€å¢åŠ è¨“ç·´è³‡æ–™

**ğŸŸ¡ Underfit (æ¬ æ“¬åˆ)ï¼š**
- ç¾è±¡ï¼šè¨“ç·´é›†å’Œæ¸¬è©¦é›†è¡¨ç¾éƒ½å¾ˆå·®
- åˆ¤æ–·ï¼šè¨“ç·´ RÂ² å’Œæ¸¬è©¦ RÂ² éƒ½å¾ˆä½ï¼ˆä¾‹å¦‚ï¼šå…©è€…éƒ½ < 0.5ï¼‰
- åŸå› ï¼šæ¨¡å‹éæ–¼ç°¡å–®ï¼Œç„¡æ³•æ•æ‰è³‡æ–™çš„æ¨¡å¼
- è§£æ±ºæ–¹æ³•ï¼šæ¸›å°‘æ­£å‰‡åŒ–å¼·åº¦ï¼ˆæ¸›å° alphaï¼‰ã€å¢åŠ ç‰¹å¾µ

**ğŸŸ¢ è‰¯å¥½æ¨¡å‹ï¼š**
- è¨“ç·´é›†å’Œæ¸¬è©¦é›†çš„ RÂ² éƒ½é«˜ä¸”ç›¸è¿‘
- ä¾‹å¦‚ï¼šè¨“ç·´ RÂ²=0.85ï¼Œæ¸¬è©¦ RÂ²=0.82
""")

# é€²è¡Œé æ¸¬
y_train_pred = model.predict(X_train)
y_test_pred = model.predict(X_test)

# è¨ˆç®—è©•ä¼°æŒ‡æ¨™
train_mse = mean_squared_error(y_train, y_train_pred)
test_mse = mean_squared_error(y_test, y_test_pred)
train_mae = mean_absolute_error(y_train, y_train_pred)
test_mae = mean_absolute_error(y_test, y_test_pred)
train_r2 = r2_score(y_train, y_train_pred)
test_r2 = r2_score(y_test, y_test_pred)

# é¡¯ç¤ºè©•ä¼°çµæœ
st.subheader("ğŸ“Š è©•ä¼°æŒ‡æ¨™çµæœ")

col1, col2 = st.columns(2)

with col1:
    st.write("### ğŸ”µ è¨“ç·´é›† (Training Set)")
    st.metric("MSE", f"{train_mse:.2f}")
    st.metric("MAE", f"{train_mae:.2f}")
    st.metric("RÂ²", f"{train_r2:.4f}")

with col2:
    st.write("### ğŸŸ¢ æ¸¬è©¦é›† (Test Set)")
    st.metric("MSE", f"{test_mse:.2f}")
    st.metric("MAE", f"{test_mae:.2f}")
    st.metric("RÂ²", f"{test_r2:.4f}")

# åˆ¤æ–· Overfit/Underfit
st.subheader("ğŸ” æ¨¡å‹è¨ºæ–·")

r2_diff = train_r2 - test_r2

if r2_diff > 0.15 and train_r2 > 0.7:
    st.warning(f"""
    **âš ï¸ åµæ¸¬åˆ°éæ“¬åˆ (Overfit)ï¼**
    
    - è¨“ç·´é›† RÂ² = {train_r2:.4f}
    - æ¸¬è©¦é›† RÂ² = {test_r2:.4f}
    - å·®ç•° = {r2_diff:.4f}
    
    **å»ºè­°**: å¢åŠ  Alpha å€¼ä»¥å¢å¼·æ­£å‰‡åŒ–ï¼Œæ¸›å°‘æ¨¡å‹è¤‡é›œåº¦ã€‚
    """)
elif train_r2 < 0.5 and test_r2 < 0.5:
    st.warning(f"""
    **âš ï¸ åµæ¸¬åˆ°æ¬ æ“¬åˆ (Underfit)ï¼**
    
    - è¨“ç·´é›† RÂ² = {train_r2:.4f}
    - æ¸¬è©¦é›† RÂ² = {test_r2:.4f}
    
    **å»ºè­°**: æ¸›å°‘ Alpha å€¼ä»¥æ¸›å¼±æ­£å‰‡åŒ–ï¼Œæˆ–å¢åŠ æ›´å¤šç‰¹å¾µã€‚
    """)
else:
    st.success(f"""
    **âœ… æ¨¡å‹è¡¨ç¾è‰¯å¥½ï¼**
    
    - è¨“ç·´é›† RÂ² = {train_r2:.4f}
    - æ¸¬è©¦é›† RÂ² = {test_r2:.4f}
    - å·®ç•° = {r2_diff:.4f}
    
    è¨“ç·´é›†èˆ‡æ¸¬è©¦é›†è¡¨ç¾ç›¸è¿‘ï¼Œæ¨¡å‹æ³›åŒ–èƒ½åŠ›ä½³ã€‚
    """)

# è¦–è¦ºåŒ–ï¼šå¯¦éš›å€¼ vs é æ¸¬å€¼
st.subheader("ğŸ“‰ é æ¸¬çµæœè¦–è¦ºåŒ–")

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))

# è¨“ç·´é›†
ax1.scatter(y_train, y_train_pred, alpha=0.6, color='blue', edgecolors='k')
ax1.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r--', lw=2)
ax1.set_xlabel('å¯¦éš›å€¼ (Actual)', fontsize=12)
ax1.set_ylabel('é æ¸¬å€¼ (Predicted)', fontsize=12)
ax1.set_title(f'è¨“ç·´é›†é æ¸¬çµæœ\nRÂ² = {train_r2:.4f}', fontsize=13)
ax1.grid(True, alpha=0.3)

# æ¸¬è©¦é›†
ax2.scatter(y_test, y_test_pred, alpha=0.6, color='green', edgecolors='k')
ax2.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
ax2.set_xlabel('å¯¦éš›å€¼ (Actual)', fontsize=12)
ax2.set_ylabel('é æ¸¬å€¼ (Predicted)', fontsize=12)
ax2.set_title(f'æ¸¬è©¦é›†é æ¸¬çµæœ\nRÂ² = {test_r2:.4f}', fontsize=13)
ax2.grid(True, alpha=0.3)

plt.tight_layout()
st.pyplot(fig)

# æ®˜å·®åœ–
st.subheader("ğŸ“Š æ®˜å·®åˆ†æ (Residual Analysis)")
st.markdown("æ®˜å·® = å¯¦éš›å€¼ - é æ¸¬å€¼ã€‚è‰¯å¥½çš„æ¨¡å‹æ®˜å·®æ‡‰è©²éš¨æ©Ÿåˆ†ä½ˆåœ¨ 0 é™„è¿‘ã€‚")

train_residuals = y_train - y_train_pred
test_residuals = y_test - y_test_pred

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))

# è¨“ç·´é›†æ®˜å·®
ax1.scatter(y_train_pred, train_residuals, alpha=0.6, color='blue', edgecolors='k')
ax1.axhline(y=0, color='r', linestyle='--', lw=2)
ax1.set_xlabel('é æ¸¬å€¼', fontsize=12)
ax1.set_ylabel('æ®˜å·®', fontsize=12)
ax1.set_title('è¨“ç·´é›†æ®˜å·®åœ–', fontsize=13)
ax1.grid(True, alpha=0.3)

# æ¸¬è©¦é›†æ®˜å·®
ax2.scatter(y_test_pred, test_residuals, alpha=0.6, color='green', edgecolors='k')
ax2.axhline(y=0, color='r', linestyle='--', lw=2)
ax2.set_xlabel('é æ¸¬å€¼', fontsize=12)
ax2.set_ylabel('æ®˜å·®', fontsize=12)
ax2.set_title('æ¸¬è©¦é›†æ®˜å·®åœ–', fontsize=13)
ax2.grid(True, alpha=0.3)

plt.tight_layout()
st.pyplot(fig)

# ==================== Step 5: éƒ¨ç½² (Deployment) ====================
st.markdown("---")
st.header("ğŸš€ Step 5: æ¨¡å‹éƒ¨ç½² (Deployment)")

st.markdown("""
**CRISP-DM éšæ®µ**: Deployment

é€™å€‹ Streamlit æ‡‰ç”¨ç¨‹å¼æœ¬èº«å°±æ˜¯ä¸€å€‹éƒ¨ç½²ç¯„ä¾‹ï¼
ä½¿ç”¨è€…å¯ä»¥é€éä»¥ä¸‹æ–¹å¼ä½¿ç”¨æ¨¡å‹ï¼š

1. **æ‰¹æ¬¡é æ¸¬**: ä¸Šå‚³æ–°çš„é­šé¡è³‡æ–™é€²è¡Œæ‰¹æ¬¡é æ¸¬
2. **å³æ™‚é æ¸¬**: è¼¸å…¥å–®ä¸€é­šé¡çš„ç‰¹å¾µé€²è¡Œå³æ™‚é æ¸¬
3. **æ¨¡å‹èª¿æ•´**: èª¿æ•´ Alpha åƒæ•¸ä¸¦å³æ™‚æŸ¥çœ‹æ•ˆæœ
""")

st.subheader("ğŸ¯ å³æ™‚é æ¸¬å·¥å…·")
st.markdown("è¼¸å…¥é­šé¡çš„ç‰¹å¾µè³‡è¨Šï¼Œæ¨¡å‹å°‡é æ¸¬å…¶é«”é‡ï¼š")

col1, col2, col3 = st.columns(3)

with col1:
    length1 = st.number_input("Length1 (å‚ç›´é•·åº¦)", min_value=0.0, max_value=100.0, value=25.0, step=0.1)
    length2 = st.number_input("Length2 (å°è§’ç·šé•·åº¦)", min_value=0.0, max_value=100.0, value=27.0, step=0.1)

with col2:
    length3 = st.number_input("Length3 (äº¤å‰é•·åº¦)", min_value=0.0, max_value=100.0, value=32.0, step=0.1)
    height = st.number_input("Height (é«˜åº¦)", min_value=0.0, max_value=50.0, value=12.0, step=0.1)

with col3:
    width = st.number_input("Width (å¯¬åº¦)", min_value=0.0, max_value=20.0, value=4.5, step=0.1)
    species = st.selectbox("Species (ç¨®é¡)", df['Species'].unique())

if st.button("ğŸ”® é€²è¡Œé æ¸¬", type="primary"):
    # æº–å‚™è¼¸å…¥è³‡æ–™
    input_data = pd.DataFrame({
        'Length1': [length1],
        'Length2': [length2],
        'Length3': [length3],
        'Height': [height],
        'Width': [width],
        'Species': [species]
    })
    
    # One-Hot Encoding
    input_encoded = pd.get_dummies(input_data, columns=['Species'], drop_first=True)
    
    # ç¢ºä¿æ‰€æœ‰ç‰¹å¾µéƒ½å­˜åœ¨
    for col in feature_names:
        if col not in input_encoded.columns:
            input_encoded[col] = 0
    
    input_encoded = input_encoded[feature_names]
    
    # æ¨™æº–åŒ–
    input_scaled = scaler.transform(input_encoded)
    
    # é æ¸¬
    prediction = model.predict(input_scaled)[0]
    
    st.success(f"### é æ¸¬çµæœ: **{prediction:.2f} å…‹**")
    
    # é¡¯ç¤ºä¿¡è³´å€é–“ï¼ˆç°¡åŒ–ç‰ˆæœ¬ï¼ŒåŸºæ–¼è¨“ç·´é›† MAEï¼‰
    confidence_interval = test_mae * 1.96  # ç´„ 95% ä¿¡è³´å€é–“
    st.info(f"95% ä¿¡è³´å€é–“: **{prediction - confidence_interval:.2f} ~ {prediction + confidence_interval:.2f} å…‹**")

# ==================== ç¸½çµ ====================
st.markdown("---")
st.header("ğŸ“ å°ˆæ¡ˆç¸½çµ")

st.markdown(f"""
### ğŸ“ æœ¬å°ˆæ¡ˆå®Œæˆé …ç›®ï¼š

âœ… **Step 1: è³‡æ–™è¼‰å…¥** - æˆåŠŸè¼‰å…¥é­šé¡è³‡æ–™é›† ({len(df)} ç­†è³‡æ–™)

âœ… **Step 2: è³‡æ–™é è™•ç†** 
- å®Œæˆ One-Hot Encoding è™•ç†é¡åˆ¥è®Šæ•¸
- è¨“ç·´/æ¸¬è©¦é›†åˆ†å‰² ({int((1-test_size)*100)}% / {int(test_size*100)}%)
- ç‰¹å¾µæ¨™æº–åŒ–

âœ… **Step 3: æ¨¡å‹å»ºç«‹** 
- ä½¿ç”¨ Lasso è¿´æ­¸ (Alpha={alpha})
- ç‰¹å¾µé¸æ“‡ï¼š{np.sum(model.coef_ != 0)} / {len(model.coef_)} å€‹ç‰¹å¾µè¢«ä¿ç•™

âœ… **Step 4: æ¨¡å‹è©•ä¼°**
- è¨“ç·´é›† RÂ² = {train_r2:.4f}
- æ¸¬è©¦é›† RÂ² = {test_r2:.4f}
- æ¸¬è©¦é›† MAE = {test_mae:.2f}

âœ… **Step 5: æ¨¡å‹éƒ¨ç½²**
- Streamlit äº’å‹•å¼æ‡‰ç”¨ç¨‹å¼
- æ”¯æ´å³æ™‚é æ¸¬åŠŸèƒ½

### ğŸ”‘ é—œéµç™¼ç¾ï¼š
- æœ€é‡è¦çš„ç‰¹å¾µï¼ˆçµ•å°ä¿‚æ•¸æœ€å¤§ï¼‰ï¼š**{coef_df.iloc[0]['ç‰¹å¾µåç¨±']}**
- æ¨¡å‹è¤‡é›œåº¦ï¼šAlpha={alpha}ï¼Œä¿ç•™ {np.sum(model.coef_ != 0)} å€‹ç‰¹å¾µ
- é æ¸¬æº–ç¢ºåº¦ï¼šæ¸¬è©¦é›† RÂ²={test_r2:.4f}ï¼Œå¹³å‡èª¤å·® {test_mae:.2f} å…‹

### ğŸ“š ä½¿ç”¨çš„æŠ€è¡“èˆ‡å¥—ä»¶ï¼š
- **Python**: Pandas, NumPy, Scikit-learn
- **è¦–è¦ºåŒ–**: Matplotlib, Seaborn
- **Webæ¡†æ¶**: Streamlit
- **æ©Ÿå™¨å­¸ç¿’**: Lasso Regression with L1 Regularization
""")

st.balloons()
st.success("ğŸ‰ å°ˆæ¡ˆå®Œæˆï¼æ„Ÿè¬ä½¿ç”¨æœ¬ç³»çµ±ï¼")