"""
é­šé¡é«”é‡é æ¸¬ç³»çµ± - ä½¿ç”¨ Lasso è¿´æ­¸èˆ‡ Optuna è¶…åƒæ•¸å„ªåŒ–
Fish Weight Prediction System using Lasso Regression with Optuna

ä½œæ¥­è¦æ±‚ï¼š
1. ä½¿ç”¨ chatGPT å·¥å…·åˆ©ç”¨ CRISP-DM æ¨¡æ¿è§£æ±ºå¤šå…ƒå›æ­¸ Regression Problem
2. Step 1: çˆ¬èŸ²æŠ“å– Boston æˆ¿åƒ¹ (æœ¬å°ˆæ¡ˆæ”¹ç”¨é­šé¡è³‡æ–™é›†)
3. Step 2: Preprocessing: train test split
4. Step 3: Build Model using Lasso
5. Step 4: Evaluation: MSE, MAE, R2 metrics çš„æ„ç¾©, overfit and underfit çš„åˆ¤æ–·, å„ªåŒ–æ¨¡å‹ Optuna
6. Step 5: Deployment

åŸ·è¡Œæ–¹å¼: streamlit run app.py
"""

import streamlit as st
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.linear_model import Lasso
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import matplotlib.pyplot as plt
import seaborn as sns
import optuna
from optuna.visualization.matplotlib import plot_optimization_history, plot_param_importances
import warnings
warnings.filterwarnings('ignore')

# è¨­å®šä¸­æ–‡å­—å‹
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'Microsoft JhengHei', 'SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# è¨­å®šé é¢é…ç½®
st.set_page_config(page_title="é­šé¡é«”é‡é æ¸¬ç³»çµ±", page_icon="ğŸŸ", layout="wide")

# PATH è®Šæ•¸è¨­å®š
PATH = "./dataset/Fishers maket.csv"

# æ¨™é¡Œ
st.title("ğŸŸ é­šé¡é«”é‡é æ¸¬ç³»çµ± - Lasso è¿´æ­¸åˆ†æ")
st.markdown("### ä½¿ç”¨ CRISP-DM æ–¹æ³•è«–èˆ‡ Optuna è¶…åƒæ•¸å„ªåŒ–")
st.markdown("---")

# å´é‚Šæ¬„åƒæ•¸è¨­å®š
st.sidebar.header("ğŸ›ï¸ åƒæ•¸è¨­å®š")
st.sidebar.subheader("ğŸ“Š è³‡æ–™åˆ†å‰²åƒæ•¸")
test_size = st.sidebar.slider("æ¸¬è©¦é›†æ¯”ä¾‹", 0.1, 0.4, 0.2, 0.05)
random_state = st.sidebar.number_input("éš¨æ©Ÿç¨®å­", 1, 100, 42)

st.sidebar.subheader("ğŸ¤– æ¨¡å‹åƒæ•¸")
use_optuna = st.sidebar.checkbox("ä½¿ç”¨ Optuna å„ªåŒ–", value=False)

if not use_optuna:
    alpha = st.sidebar.slider("Alpha (æ­£å‰‡åŒ–å¼·åº¦)", 0.01, 10.0, 1.0, 0.1)
else:
    st.sidebar.info("âœ¨ Optuna å°‡è‡ªå‹•å°‹æ‰¾æœ€ä½³ Alpha å€¼")
    n_trials = st.sidebar.slider("Optuna è©¦é©—æ¬¡æ•¸", 10, 200, 50, 10)

# è¼‰å…¥è³‡æ–™
@st.cache_data
def load_data(file_path):
    try:
        df = pd.read_csv(file_path)
        return df, None
    except Exception as e:
        return None, str(e)

df, error = load_data(PATH)

if error:
    st.error(f"âŒ {error}")
    st.stop()

# è³‡æ–™é è™•ç†
@st.cache_data
def preprocess_data(dataframe, test_sz, rand_state):
    X = dataframe.drop('Weight', axis=1)
    y = dataframe['Weight']
    
    if 'Species' in X.columns:
        X = pd.get_dummies(X, columns=['Species'], drop_first=True)
    
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_sz, random_state=rand_state
    )
    
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    return X_train_scaled, X_test_scaled, y_train, y_test, scaler, X.columns

X_train, X_test, y_train, y_test, scaler, feature_names = preprocess_data(df, test_size, random_state)

# Optuna å„ªåŒ–å‡½æ•¸
def objective(trial, X_tr, y_tr):
    alpha_param = trial.suggest_float('alpha', 0.001, 10.0, log=True)
    model = Lasso(alpha=alpha_param, random_state=42, max_iter=10000)
    scores = cross_val_score(model, X_tr, y_tr, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)
    return -scores.mean()

@st.cache_resource
def optimize_with_optuna(X_tr, y_tr, n_trials_param):
    study = optuna.create_study(direction='minimize', study_name='lasso_optimization')
    study.optimize(lambda trial: objective(trial, X_tr, y_tr), n_trials=n_trials_param, show_progress_bar=False)
    return study

# è¨“ç·´æ¨¡å‹
@st.cache_resource
def train_lasso_model(X_tr, y_tr, alpha_param):
    model = Lasso(alpha=alpha_param, random_state=42, max_iter=10000)
    model.fit(X_tr, y_tr)
    return model

# æ¨¡å‹è©•ä¼°å‡½æ•¸
def evaluate_model(model, X_tr, X_te, y_tr, y_te):
    y_train_pred = model.predict(X_tr)
    y_test_pred = model.predict(X_te)
    
    return {
        'train': {
            'mse': mean_squared_error(y_tr, y_train_pred),
            'mae': mean_absolute_error(y_tr, y_train_pred),
            'r2': r2_score(y_tr, y_train_pred)
        },
        'test': {
            'mse': mean_squared_error(y_te, y_test_pred),
            'mae': mean_absolute_error(y_te, y_test_pred),
            'r2': r2_score(y_te, y_test_pred)
        },
        'predictions': {
            'train': (y_tr, y_train_pred),
            'test': (y_te, y_test_pred)
        }
    }

# ä¸»è¦ Tabs
tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
    "ğŸ“Š Step 1: è³‡æ–™è¼‰å…¥", 
    "âš™ï¸ Step 2: è³‡æ–™é è™•ç†",
    "ğŸ¤– Step 3: æ¨¡å‹å»ºç«‹",
    "ğŸ“ˆ Step 4: æ¨¡å‹è©•ä¼°",
    "âœ¨ Step 4+: Optuna å„ªåŒ–",
    "ğŸš€ Step 5: æ¨¡å‹éƒ¨ç½²"
])

# Tab 1: è³‡æ–™è¼‰å…¥
with tab1:
    st.header("ğŸ“Š Step 1: è³‡æ–™è¼‰å…¥")
    st.markdown("**CRISP-DM éšæ®µ**: Business Understanding & Data Understanding")
    st.success(f"âœ… æˆåŠŸè¼‰å…¥è³‡æ–™ï¼æª”æ¡ˆè·¯å¾‘: {PATH}")
    
    col1, col2 = st.columns([2, 1])
    with col1:
        st.subheader("ğŸ“‹ è³‡æ–™é è¦½")
        st.dataframe(df.head(15), use_container_width=True)
    
    with col2:
        st.subheader("ğŸ“Š è³‡æ–™è³‡è¨Š")
        st.metric("ç¸½æ¨£æœ¬æ•¸", len(df))
        st.metric("ç‰¹å¾µæ•¸é‡", len(df.columns) - 1)
        st.metric("ç¼ºå¤±å€¼ç¸½æ•¸", df.isnull().sum().sum())
    
    st.subheader("ğŸ“ˆ æè¿°æ€§çµ±è¨ˆ")
    st.dataframe(df.describe(), use_container_width=True)
    
    st.subheader("ğŸ¯ ç›®æ¨™è®Šæ•¸ (Weight) åˆ†ä½ˆ")
    fig, ax = plt.subplots(figsize=(10, 4))
    ax.hist(df['Weight'], bins=20, color='skyblue', edgecolor='black', alpha=0.7)
    ax.set_xlabel('é«”é‡ (Weight)', fontsize=12)
    ax.set_ylabel('é »ç‡', fontsize=12)
    ax.set_title('é­šé¡é«”é‡åˆ†ä½ˆåœ–', fontsize=14, fontweight='bold')
    ax.grid(True, alpha=0.3)
    st.pyplot(fig)
    plt.close()

# Tab 2: è³‡æ–™é è™•ç†
with tab2:
    st.header("âš™ï¸ Step 2: è³‡æ–™é è™•ç†èˆ‡åˆ†å‰²")
    st.markdown("**CRISP-DM éšæ®µ**: Data Preparation")
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("è¨“ç·´é›†æ¨£æœ¬æ•¸", len(X_train))
    with col2:
        st.metric("æ¸¬è©¦é›†æ¨£æœ¬æ•¸", len(X_test))
    with col3:
        st.metric("ç‰¹å¾µæ•¸é‡ï¼ˆç·¨ç¢¼å¾Œï¼‰", X_train.shape[1])
    
    st.success("âœ… è³‡æ–™é è™•ç†å®Œæˆï¼")
    
    st.subheader("ğŸ“‹ è™•ç†å¾Œçš„ç‰¹å¾µåˆ—è¡¨")
    st.write(list(feature_names))
    
    st.subheader("ğŸ”¥ ç‰¹å¾µç›¸é—œæ€§ç†±åœ–")
    X_df = pd.DataFrame(X_train, columns=feature_names)
    X_df['Weight'] = y_train.values
    
    fig, ax = plt.subplots(figsize=(10, 8))
    sns.heatmap(X_df.corr(), annot=True, fmt='.2f', cmap='coolwarm', center=0, ax=ax)
    ax.set_title('ç‰¹å¾µç›¸é—œæ€§çŸ©é™£', fontsize=14, fontweight='bold')
    plt.tight_layout()
    st.pyplot(fig)
    plt.close()

# Tab 3: æ¨¡å‹å»ºç«‹
with tab3:
    st.header("ğŸ¤– Step 3: å»ºç«‹æ¨¡å‹ - Lasso è¿´æ­¸")
    st.markdown("**CRISP-DM éšæ®µ**: Modeling")
    
    if use_optuna:
        st.info("ğŸ”„ ä½¿ç”¨ Optuna å°‹æ‰¾æœ€ä½³ Alpha å€¼...")
        with st.spinner("æ­£åœ¨å„ªåŒ–è¶…åƒæ•¸..."):
            study = optimize_with_optuna(X_train, y_train, n_trials)
            best_alpha = study.best_params['alpha']
            st.success(f"âœ… Optuna å„ªåŒ–å®Œæˆï¼æœ€ä½³ Alpha = {best_alpha:.6f}")
        
        model = train_lasso_model(X_train, y_train, best_alpha)
        current_alpha = best_alpha
    else:
        model = train_lasso_model(X_train, y_train, alpha)
        current_alpha = alpha
        st.success(f"âœ… Lasso æ¨¡å‹è¨“ç·´å®Œæˆï¼Alpha = {current_alpha}")
    
    st.subheader("ğŸ“Š ç‰¹å¾µä¿‚æ•¸")
    coef_df = pd.DataFrame({
        'ç‰¹å¾µåç¨±': feature_names,
        'ä¿‚æ•¸': model.coef_,
        'çµ•å°å€¼': np.abs(model.coef_)
    }).sort_values('çµ•å°å€¼', ascending=False)
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        fig, ax = plt.subplots(figsize=(10, 6))
        colors = ['green' if x != 0 else 'lightgray' for x in coef_df['ä¿‚æ•¸']]
        ax.barh(coef_df['ç‰¹å¾µåç¨±'], coef_df['ä¿‚æ•¸'], color=colors, edgecolor='black')
        ax.set_xlabel('ä¿‚æ•¸å€¼', fontsize=12)
        ax.set_title('Lasso è¿´æ­¸ç‰¹å¾µä¿‚æ•¸', fontsize=14, fontweight='bold')
        ax.axvline(x=0, color='black', linestyle='--', linewidth=1)
        ax.grid(True, alpha=0.3, axis='x')
        plt.tight_layout()
        st.pyplot(fig)
        plt.close()
    
    with col2:
        st.dataframe(coef_df, use_container_width=True, height=400)
    
    non_zero = np.sum(model.coef_ != 0)
    total = len(model.coef_)
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ä¿ç•™ç‰¹å¾µæ•¸", non_zero)
    with col2:
        st.metric("æ’é™¤ç‰¹å¾µæ•¸", total - non_zero)
    with col3:
        st.metric("ç‰¹å¾µä¿ç•™ç‡", f"{non_zero/total*100:.1f}%")

# Tab 4: æ¨¡å‹è©•ä¼°
with tab4:
    st.header("ğŸ“ˆ Step 4: æ¨¡å‹è©•ä¼°")
    st.markdown("**CRISP-DM éšæ®µ**: Evaluation")
    
    metrics = evaluate_model(model, X_train, X_test, y_train, y_test)
    
    st.subheader("ğŸ“Š è©•ä¼°æŒ‡æ¨™çµæœ")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("### ğŸ”µ è¨“ç·´é›† (Training Set)")
        st.metric("MSE", f"{metrics['train']['mse']:.2f}")
        st.metric("MAE", f"{metrics['train']['mae']:.2f}")
        st.metric("RÂ²", f"{metrics['train']['r2']:.4f}")
    
    with col2:
        st.write("### ğŸŸ¢ æ¸¬è©¦é›† (Test Set)")
        st.metric("MSE", f"{metrics['test']['mse']:.2f}")
        st.metric("MAE", f"{metrics['test']['mae']:.2f}")
        st.metric("RÂ²", f"{metrics['test']['r2']:.4f}")
    
    st.subheader("ğŸ” æ¨¡å‹è¨ºæ–· - Overfit/Underfit åˆ¤æ–·")
    
    train_r2 = metrics['train']['r2']
    test_r2 = metrics['test']['r2']
    r2_diff = train_r2 - test_r2
    
    if r2_diff > 0.15 and train_r2 > 0.7:
        st.warning(f"**âš ï¸ åµæ¸¬åˆ°éæ“¬åˆ (Overfit)ï¼** è¨“ç·´ RÂ²={train_r2:.4f}, æ¸¬è©¦ RÂ²={test_r2:.4f}, å·®ç•°={r2_diff:.4f}")
    elif train_r2 < 0.5 and test_r2 < 0.5:
        st.warning(f"**âš ï¸ åµæ¸¬åˆ°æ¬ æ“¬åˆ (Underfit)ï¼** è¨“ç·´ RÂ²={train_r2:.4f}, æ¸¬è©¦ RÂ²={test_r2:.4f}")
    else:
        st.success(f"**âœ… æ¨¡å‹è¡¨ç¾è‰¯å¥½ï¼** è¨“ç·´ RÂ²={train_r2:.4f}, æ¸¬è©¦ RÂ²={test_r2:.4f}, å·®ç•°={r2_diff:.4f}")
    
    st.subheader("ğŸ“‰ é æ¸¬çµæœè¦–è¦ºåŒ–")
    
    y_tr, y_train_pred = metrics['predictions']['train']
    y_te, y_test_pred = metrics['predictions']['test']
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))
    
    ax1.scatter(y_tr, y_train_pred, alpha=0.6, color='blue', edgecolors='k', s=50)
    ax1.plot([y_tr.min(), y_tr.max()], [y_tr.min(), y_tr.max()], 'r--', lw=2)
    ax1.set_xlabel('å¯¦éš›å€¼', fontsize=12)
    ax1.set_ylabel('é æ¸¬å€¼', fontsize=12)
    ax1.set_title(f'è¨“ç·´é›† (RÂ²={train_r2:.4f})', fontsize=13, fontweight='bold')
    ax1.grid(True, alpha=0.3)
    
    ax2.scatter(y_te, y_test_pred, alpha=0.6, color='green', edgecolors='k', s=50)
    ax2.plot([y_te.min(), y_te.max()], [y_te.min(), y_te.max()], 'r--', lw=2)
    ax2.set_xlabel('å¯¦éš›å€¼', fontsize=12)
    ax2.set_ylabel('é æ¸¬å€¼', fontsize=12)
    ax2.set_title(f'æ¸¬è©¦é›† (RÂ²={test_r2:.4f})', fontsize=13, fontweight='bold')
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    st.pyplot(fig)
    plt.close()
    
    st.subheader("ğŸ“Š æ®˜å·®åˆ†æ")
    train_residuals = y_tr - y_train_pred
    test_residuals = y_te - y_test_pred
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))
    
    ax1.scatter(y_train_pred, train_residuals, alpha=0.6, color='blue', edgecolors='k', s=50)
    ax1.axhline(y=0, color='r', linestyle='--', lw=2)
    ax1.set_xlabel('é æ¸¬å€¼', fontsize=12)
    ax1.set_ylabel('æ®˜å·®', fontsize=12)
    ax1.set_title('è¨“ç·´é›†æ®˜å·®åœ–', fontsize=13, fontweight='bold')
    ax1.grid(True, alpha=0.3)
    
    ax2.scatter(y_test_pred, test_residuals, alpha=0.6, color='green', edgecolors='k', s=50)
    ax2.axhline(y=0, color='r', linestyle='--', lw=2)
    ax2.set_xlabel('é æ¸¬å€¼', fontsize=12)
    ax2.set_ylabel('æ®˜å·®', fontsize=12)
    ax2.set_title('æ¸¬è©¦é›†æ®˜å·®åœ–', fontsize=13, fontweight='bold')
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    st.pyplot(fig)
    plt.close()

# Tab 5: Optuna å„ªåŒ–
with tab5:
    st.header("âœ¨ Step 4+: ä½¿ç”¨ Optuna å„ªåŒ–æ¨¡å‹")
    
    st.markdown("""
    **ä»€éº¼æ˜¯ Optunaï¼Ÿ**
    
    Optuna æ˜¯ä¸€å€‹è‡ªå‹•åŒ–è¶…åƒæ•¸å„ªåŒ–æ¡†æ¶ï¼Œå¯ä»¥å¹«åŠ©æˆ‘å€‘æ‰¾åˆ°æœ€ä½³çš„æ¨¡å‹åƒæ•¸ã€‚
    
    ### Optuna çš„å„ªå‹¢ï¼š
    - ğŸ¯ **è‡ªå‹•åŒ–æœå°‹**: è‡ªå‹•æ¢ç´¢åƒæ•¸ç©ºé–“
    - ğŸ“Š **é«˜æ•ˆç‡**: ä½¿ç”¨ TPE æ¼”ç®—æ³•ï¼Œæ¯”ç¶²æ ¼æœå°‹æ›´å¿«
    - ğŸ“ˆ **è¦–è¦ºåŒ–**: æä¾›è±å¯Œçš„è¦–è¦ºåŒ–å·¥å…·
    """)
    
    if not use_optuna:
        st.info("ğŸ’¡ è«‹åœ¨å·¦å´é‚Šæ¬„å‹¾é¸ã€Œä½¿ç”¨ Optuna å„ªåŒ–ã€ä¾†å•Ÿç”¨è¶…åƒæ•¸å„ªåŒ–åŠŸèƒ½")
    else:
        st.success(f"âœ… Optuna å„ªåŒ–å·²å•Ÿç”¨ï¼å·²å®Œæˆ {n_trials} æ¬¡è©¦é©—")
        
        st.subheader("ğŸ† æœ€ä½³åƒæ•¸")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("æœ€ä½³ Alpha", f"{study.best_params['alpha']:.6f}")
        with col2:
            st.metric("æœ€ä½³ MSE", f"{study.best_value:.2f}")
        with col3:
            st.metric("å®Œæˆè©¦é©—æ•¸", len(study.trials))
        
        st.subheader("ğŸ“ˆ å„ªåŒ–æ­·å²")
        try:
            fig = plot_optimization_history(study)
            fig.set_figwidth(10)
            fig.set_figheight(5)
            st.pyplot(fig)
            plt.close()
        except Exception as e:
            st.warning(f"ç„¡æ³•é¡¯ç¤ºå„ªåŒ–æ­·å²åœ–: {str(e)}")
            # æ‰‹å‹•ç¹ªè£½å„ªåŒ–æ­·å²
            trials_values = [trial.value for trial in study.trials]
            fig, ax = plt.subplots(figsize=(10, 5))
            ax.plot(trials_values, marker='o', linestyle='-', alpha=0.7)
            ax.set_xlabel('è©¦é©—æ¬¡æ•¸', fontsize=12)
            ax.set_ylabel('ç›®æ¨™å€¼ (MSE)', fontsize=12)
            ax.set_title('å„ªåŒ–æ­·å²', fontsize=14, fontweight='bold')
            ax.grid(True, alpha=0.3)
            st.pyplot(fig)
            plt.close()
        
        st.subheader("ğŸ“Š æ‰€æœ‰è©¦é©—çµæœ")
        trials_df = study.trials_dataframe()
        trials_df = trials_df[['number', 'value', 'params_alpha', 'state']]
        trials_df.columns = ['è©¦é©—ç·¨è™Ÿ', 'MSE', 'Alpha', 'ç‹€æ…‹']
        trials_df = trials_df.sort_values('MSE')
        st.dataframe(trials_df.head(20), use_container_width=True)
        
        st.subheader("ğŸ“Š Alpha åƒæ•¸åˆ†ä½ˆ")
        fig, ax = plt.subplots(figsize=(10, 4))
        ax.scatter(trials_df['Alpha'], trials_df['MSE'], alpha=0.6, s=50, edgecolors='k')
        ax.axvline(x=study.best_params['alpha'], color='r', linestyle='--', lw=2, 
                   label=f"æœ€ä½³ Alpha = {study.best_params['alpha']:.4f}")
        ax.set_xlabel('Alpha å€¼', fontsize=12)
        ax.set_ylabel('MSE', fontsize=12)
        ax.set_title('Alpha åƒæ•¸èˆ‡ MSE çš„é—œä¿‚', fontsize=14, fontweight='bold')
        ax.set_xscale('log')
        ax.legend()
        ax.grid(True, alpha=0.3)
        plt.tight_layout()
        st.pyplot(fig)
        plt.close()
        
        st.subheader("âš–ï¸ å„ªåŒ–æ•ˆæœæ¯”è¼ƒ")
        default_model = train_lasso_model(X_train, y_train, 1.0)
        default_metrics = evaluate_model(default_model, X_train, X_test, y_train, y_test)
        
        comparison_df = pd.DataFrame({
            'æ¨¡å‹': ['é è¨­ Alpha (1.0)', f'Optuna æœ€ä½³ Alpha ({study.best_params["alpha"]:.4f})'],
            'è¨“ç·´é›† RÂ²': [default_metrics['train']['r2'], metrics['train']['r2']],
            'æ¸¬è©¦é›† RÂ²': [default_metrics['test']['r2'], metrics['test']['r2']],
            'æ¸¬è©¦é›† MSE': [default_metrics['test']['mse'], metrics['test']['mse']],
            'æ¸¬è©¦é›† MAE': [default_metrics['test']['mae'], metrics['test']['mae']]
        })
        
        st.dataframe(comparison_df, use_container_width=True)
        
        improvement_r2 = ((metrics['test']['r2'] - default_metrics['test']['r2']) / 
                         abs(default_metrics['test']['r2']) * 100)
        improvement_mse = ((default_metrics['test']['mse'] - metrics['test']['mse']) / 
                          default_metrics['test']['mse'] * 100)
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric("RÂ² æ”¹å–„", f"{improvement_r2:+.2f}%")
        with col2:
            st.metric("MSE æ”¹å–„", f"{improvement_mse:+.2f}%")

# Tab 6: æ¨¡å‹éƒ¨ç½²
with tab6:
    st.header("ğŸš€ Step 5: æ¨¡å‹éƒ¨ç½²")
    st.markdown("**CRISP-DM éšæ®µ**: Deployment")
    
    deploy_tab1, deploy_tab2 = st.tabs(["ğŸ¯ å³æ™‚é æ¸¬", "ğŸ“¤ æ‰¹æ¬¡é æ¸¬"])
    
    with deploy_tab1:
        st.subheader("ğŸ¯ å³æ™‚é æ¸¬å·¥å…·")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            length1 = st.number_input("Length1", 0.0, 100.0, 25.0, 0.1)
            length2 = st.number_input("Length2", 0.0, 100.0, 27.0, 0.1)
        
        with col2:
            length3 = st.number_input("Length3", 0.0, 100.0, 32.0, 0.1)
            height = st.number_input("Height", 0.0, 50.0, 12.0, 0.1)
        
        with col3:
            width = st.number_input("Width", 0.0, 20.0, 4.5, 0.1)
            species = st.selectbox("Species", df['Species'].unique())
        
        if st.button("ğŸ”® é€²è¡Œé æ¸¬", type="primary"):
            input_data = pd.DataFrame({
                'Length1': [length1], 'Length2': [length2], 'Length3': [length3],
                'Height': [height], 'Width': [width], 'Species': [species]
            })
            
            input_encoded = pd.get_dummies(input_data, columns=['Species'], drop_first=True)
            for col in feature_names:
                if col not in input_encoded.columns:
                    input_encoded[col] = 0
            input_encoded = input_encoded[feature_names]
            
            input_scaled = scaler.transform(input_encoded)
            prediction = model.predict(input_scaled)[0]
            
            st.success(f"### ğŸ¯ é æ¸¬çµæœ: **{prediction:.2f} å…‹**")
            
            confidence_interval = metrics['test']['mae'] * 1.96
            st.info(f"ğŸ“Š 95% ä¿¡è³´å€é–“: **{prediction - confidence_interval:.2f} ~ {prediction + confidence_interval:.2f} å…‹**")
    
    with deploy_tab2:
        st.subheader("ğŸ“¤ æ‰¹æ¬¡é æ¸¬å·¥å…·")
        uploaded_file = st.file_uploader("ä¸Šå‚³ CSV æª”æ¡ˆ", type=['csv'])
        
        if uploaded_file is not None:
            batch_df = pd.read_csv(uploaded_file)
            st.dataframe(batch_df.head(), use_container_width=True)
            
            if st.button("ğŸš€ é–‹å§‹æ‰¹æ¬¡é æ¸¬", type="primary"):
                has_weight = 'Weight' in batch_df.columns
                X_batch = batch_df.drop('Weight', axis=1) if has_weight else batch_df.copy()
                
                if 'Species' in X_batch.columns:
                    X_batch_encoded = pd.get_dummies(X_batch, columns=['Species'], drop_first=True)
                else:
                    X_batch_encoded = X_batch.copy()
                
                for col in feature_names:
                    if col not in X_batch_encoded.columns:
                        X_batch_encoded[col] = 0
                
                X_batch_encoded = X_batch_encoded[feature_names]
                X_batch_scaled = scaler.transform(X_batch_encoded)
                predictions = model.predict(X_batch_scaled)
                
                results_df = batch_df.copy()
                results_df['é æ¸¬é«”é‡'] = predictions
                
                st.success(f"âœ… æ‰¹æ¬¡é æ¸¬å®Œæˆï¼å…± {len(predictions)} ç­†")
                st.dataframe(results_df, use_container_width=True)
                
                csv = results_df.to_csv(index=False).encode('utf-8-sig')
                st.download_button("ğŸ“¥ ä¸‹è¼‰çµæœ", csv, "predictions.csv", "text/csv", type="primary")

# é å°¾ç¸½çµ
st.markdown("---")
st.header("ğŸ“ å°ˆæ¡ˆç¸½çµ")

col1, col2 = st.columns(2)

with col1:
    st.markdown(f"""
    ### âœ… å®Œæˆé …ç›®
    
    - âœ… è¼‰å…¥ {len(df)} ç­†é­šé¡è³‡æ–™
    - âœ… è³‡æ–™é è™•ç†èˆ‡åˆ†å‰²
    - âœ… Lasso è¿´æ­¸æ¨¡å‹ (Alpha={current_alpha:.6f})
    - âœ… ä¿ç•™ {np.sum(model.coef_ != 0)}/{len(model.coef_)} å€‹ç‰¹å¾µ
    - âœ… {'Optuna è¶…åƒæ•¸å„ªåŒ–' if use_optuna else 'æ‰‹å‹•åƒæ•¸è¨­å®š'}
    """)

with col2:
    st.markdown(f"""
    ### ğŸ“Š æ¨¡å‹æ•ˆèƒ½
    
    - è¨“ç·´é›† RÂ² = {metrics['train']['r2']:.4f}
    - æ¸¬è©¦é›† RÂ² = {metrics['test']['r2']:.4f}
    - æ¸¬è©¦é›† MAE = {metrics['test']['mae']:.2f} å…‹
    - æœ€é‡è¦ç‰¹å¾µ: {coef_df.iloc[0]['ç‰¹å¾µåç¨±']}
    """)

st.balloons()
st.success("ğŸ‰ å°ˆæ¡ˆå®Œæˆï¼æ„Ÿè¬ä½¿ç”¨æœ¬ç³»çµ±ï¼")

st.sidebar.markdown("---")
st.sidebar.info("""
### ğŸ’¡ ä½¿ç”¨æç¤º

1. èª¿æ•´åƒæ•¸å¾Œæ¨¡å‹è‡ªå‹•é‡æ–°è¨“ç·´
2. ä½¿ç”¨ Optuna æ‰¾åˆ°æœ€ä½³ Alpha
3. åˆ‡æ› Tab æŸ¥çœ‹å„æ­¥é©Ÿ
4. åœ¨ã€Œæ¨¡å‹éƒ¨ç½²ã€é€²è¡Œé æ¸¬
""")